from utils.utils import *
import utils.loss as uloss
import utils.metric as me

class EvalLRP(SaveableObject):
	"""For processing .lrpd file"""
	def __init__(self, config_data, output_folder_name, save_name='EvalLrp.evlrp', verbose=0):
		super(EvalLRP, self).__init__()
		self.verbose = verbose
		if verbose>100: print("Initiating EvalLRP() from utils.evalobj.py")
		self.model_dir = os.path.join(config_data['working_dir'], config_data['relative_checkpoint_dir'],config_data['model_label_name'])
		self.lrp_folder_dir = None
		if verbose>100: print("  Setting up model_dir:%s"%(self.model_dir))
		self.frange = None
		self.crange = None

		self.pfilter_data_0002 = {}
		self.cfilter_data_0002 = {}

		'''
		self.pfilter_data_0002 = {
			filter_interval_1 : [	this_unit, ... ],
			filter_interval_2 : [	this_unit, ... ],
			...
		}		
		where this_unit = {
			'case_number': ...,
			'normalized_mean':{
				'factor': ..., 
				'values':...
				}
			}
		'''
		self.pfilter_data_0003 = {}
		self.cfilter_data_0003 = {}
		'''
		self.pfilter_data_0003 = {
			filter_interval : [this_unit,...]
		}
		where this_unit = {
			'case_number': ...,
			'bLRPtoOT': bLRPtoOT_metric, # by channel, hence the size is for example (6,)
			'bLRPtobx': bLRPtobx_metric
		}
		cross_compared_value has the shape (channel_size,) i.e. each channel has a computed metric value
		'''

		self.set_lrp_folder_dir(output_folder_name)
		if not os.path.exists(self.lrp_folder_dir): os.mkdir(self.lrp_folder_dir)
		self.save_fullpath = os.path.join(self.lrp_folder_dir,save_name)


		self.THRESHOLD_binarized_LRP_to_groundtruth = 0.5
		self.THRESHOLD_binarized_LRP_to_binarized_x = 0.1

	def prepare_unit_0003(self, case_number, data_input):
		this_unit = {
			'case_number': case_number,
			'bLRPtoOT': self.cross_comparison(data_input, 'binarized_LRP_to_groundtruth') ,
			'bLRPtobx': self.cross_comparison(data_input, 'binarized_LRP_to_binarized_input')
		}
		return this_unit

	def do_DEBUG_EvalLRP_0003_LOOP(self,DEBUG_EvalLRP_0003_LOOP, data_input, this_filter_name):
		DEBUG_EvalLRP_0003_LOOP_signal = False
		if DEBUG_EvalLRP_0003_LOOP: 
			DEBUG_EvalLRP_0003_LOOP_signal = True
			self.cross_comparison_debug(data_input, 'binarized_LRP_to_groundtruth', header_text=this_filter_name)
			self.cross_comparison_debug(data_input, 'binarized_LRP_to_binarized_input', header_text=this_filter_name)				
		return DEBUG_EvalLRP_0003_LOOP_signal

	def process_one_case_mode_0003(self, lrp_output_dictionary, x1, case_number, verbose=0):
		# x0 is raw input, y0 is ground truth
		if verbose>=240: print("    Processing mode:0003")
		
		yOT = lrp_output_dictionary['OT']
		y = lrp_output_dictionary['y']

		lrp_raw = lrp_output_dictionary['raw']
		data_input = {'lrp_filtered': lrp_raw,'OT': yOT, 'x': x1 }
		this_unit = self.prepare_unit_0003(case_number, data_input)
		if 'raw' not in self.pfilter_data_0003: self.pfilter_data_0003['raw'] = [this_unit]
		else: self.pfilter_data_0003['raw'].append(this_unit)

		this_filter_name = 'fraction_pass_filter'
		for filter_interval in self.frange:			
			xkey = (this_filter_name, filter_interval[0], filter_interval[1])
			lrp_filtered = lrp_output_dictionary[xkey]
			if verbose>=240: print("      xkey:%s\n        lrp_filtered.shape:%s"%(str(xkey),str(lrp_filtered.shape)))			
			data_input = {'lrp_filtered': lrp_filtered,'OT': yOT, 'x': x1}
			if self.do_DEBUG_EvalLRP_0003_LOOP(DEBUG_EvalLRP_0003_LOOP, data_input, this_filter_name): break
			this_unit = self.prepare_unit_0003(case_number, data_input)
			if filter_interval not in self.pfilter_data_0003: self.pfilter_data_0003[filter_interval] = [this_unit]
			else: self.pfilter_data_0003[filter_interval].append(this_unit)	

		this_filter_name = 'fraction_clamp_filter'
		for filter_interval in self.crange:
			xkey = (this_filter_name, filter_interval[0], filter_interval[1])
			lrp_filtered = lrp_output_dictionary[xkey]			
			data_input = {'lrp_filtered': lrp_filtered,'OT': yOT, 'x': x1}
			if self.do_DEBUG_EvalLRP_0003_LOOP(DEBUG_EvalLRP_0003_LOOP, data_input, this_filter_name): break
			this_unit = self.prepare_unit_0003(case_number, data_input)
			if filter_interval not in self.cfilter_data_0003: self.cfilter_data_0003[filter_interval] = [this_unit]
			else: self.cfilter_data_0003[filter_interval].append(this_unit)
		return

	def cross_comparison(self, data_input, cross_comparison_mode):
		"""
		This function tries to compare quantify the interpretability of LRP output.
		The baseline for comparison will be arbitrarily chosen. For example, given 2 LRP output,
		  one raw x0 and one filtered x1, the metric is generated by comparing m(x0,y0T) with m(x1,OT)
		  where OT is the ground truth segmentation. Select the desired mode of comparison. 
		data_input format is mode-dependent 
		"""
		
		if cross_comparison_mode == 'binarized_LRP_to_groundtruth':
			lrp_filtered = data_input['lrp_filtered']
			yOT = data_input['OT']
			yLRPmetric = np.zeros(len(lrp_filtered))
			
			for i in range(len(lrp_filtered)):
				abs_max = np.max(np.abs(lrp_filtered[i].reshape(-1)))
				if abs_max > 0.:
					lrp_filtered[i] = lrp_filtered[i]/abs_max
				if any(np.isnan(lrp_filtered[i].reshape(-1))):
					print('    nan detected [%s]'%(str(i)))
					continue
				lrp_filtered[i] = np.abs(lrp_filtered[i])
				lrp_filtered[i] = np.array(lrp_filtered[i]>self.THRESHOLD_binarized_LRP_to_groundtruth,dtype=np.float)
				yLRPmetric[i] = intersect_fraction_a_in_b(lrp_filtered[i],yOT) #from utils.utils
		
		elif cross_comparison_mode == 'binarized_LRP_to_binarized_input':
			lrp_filtered = data_input['lrp_filtered']
			x = data_input['x']
			yLRPmetric = np.zeros(len(lrp_filtered))

			for i in range(len(lrp_filtered)):
				abs_max = np.max(np.abs(lrp_filtered[i].reshape(-1)))
				if abs_max > 0.:
					lrp_filtered[i] = lrp_filtered[i]/abs_max
				lrp_filtered[i] = np.abs(lrp_filtered[i])
				lrp_filtered[i] = np.array(lrp_filtered[i]>self.THRESHOLD_binarized_LRP_to_groundtruth,dtype=np.float)

				abs_max_x = np.max(np.abs(x[i].reshape(-1)))
				if abs_max_x>0:				
					x[i] = x[i]/abs_max_x
				x[i] = np.abs(x[i])
				x[i] = np.array(x[i]>self.THRESHOLD_binarized_LRP_to_binarized_x,dtype=np.float)

				yLRPmetric[i] = intersect_fraction_a_in_b(lrp_filtered[i],x[i]) #from utils.utils

		return yLRPmetric

	def cross_comparison_debug(self, data_input, cross_comparison_mode, header_text=None):
		txt = "        cross_comparison_debug()." 
		if header_text is not None: txt = txt + header_text
		print(txt)
		INTERNAL_DEBUG_SIGNAL_0 = 1
		INTERNAL_DEBUG_SIGNAL_1 = 0
		INTERNAL_DEBUG_SIGNAL_2 = 1
		INTERNAL_DEBUG_SIGNAL_3 = 0
		if cross_comparison_mode == 'binarized_LRP_to_groundtruth':
			lrp_filtered = data_input['lrp_filtered']
			yOT = data_input['OT']
			yLRPmetric = np.zeros(len(lrp_filtered))
			
			for i in range(len(lrp_filtered)):
				lrp_filtered[i] = lrp_filtered[i]/np.max(np.abs(lrp_filtered[i].reshape(-1)))
				lrp_filtered[i] = np.abs(lrp_filtered[i])
				lrp_filtered[i] = np.array(lrp_filtered[i]>self.THRESHOLD_binarized_LRP_to_groundtruth,dtype=np.float)
				yLRPmetric[i] = intersect_fraction_a_in_b(lrp_filtered[i],yOT)

			if INTERNAL_DEBUG_SIGNAL_0:
				print('          lrp_filtered.shape:%s'%(str(lrp_filtered.shape)))
				print('          yOT.shape         :%s'%(str(yOT.shape)))
				print('          yLRPmetric        :%s'%(str(yLRPmetric)))

			if INTERNAL_DEBUG_SIGNAL_1:
				fig = plt.figure()
				ax = fig.add_subplot(211)
				ax.hist(yOT.reshape(-1))
				ax.set_title('yOT')
				ax2 = fig.add_subplot(212)
				ax2.hist(lrp_filtered[0].reshape(-1))
				ax2.set_title('lrp_filtered[0]')
				plt.show()

		elif cross_comparison_mode == 'binarized_LRP_to_binarized_input':
			lrp_filtered = data_input['lrp_filtered']
			x = data_input['x']
			yLRPmetric = np.zeros(len(lrp_filtered))

			for i in range(len(lrp_filtered)):
				lrp_filtered[i] = lrp_filtered[i]/np.max(np.abs(lrp_filtered[i].reshape(-1)))
				lrp_filtered[i] = np.abs(lrp_filtered[i])
				lrp_filtered[i] = np.array(lrp_filtered[i]>self.THRESHOLD_binarized_LRP_to_groundtruth,dtype=np.float)
				
				x[i] = x[i]/np.max(np.abs(x[i].reshape(-1)))
				x[i] = np.abs(x[i])
				x[i] = np.array(x[i]>self.THRESHOLD_binarized_LRP_to_binarized_x,dtype=np.float)

				yLRPmetric[i] = intersect_fraction_a_in_b(lrp_filtered[i],x[i]) #from utils.utils
			
			if INTERNAL_DEBUG_SIGNAL_2:
				print('          lrp_filtered.shape:%s'%(str(lrp_filtered.shape)))
				print('          x.shape         :%s'%(str(x.shape)))
				print('          yLRPmetric        :%s'%(str(yLRPmetric)))
			
			if INTERNAL_DEBUG_SIGNAL_3:
				fig = plt.figure()
				ax = fig.add_subplot(211)
				ax.hist(x.reshape(-1))
				ax.set_title('x')
				ax2 = fig.add_subplot(212)
				ax2.hist(lrp_filtered[0].reshape(-1))
				ax2.set_title('lrp_filtered[0]')
				plt.show()
		return yLRPmetric

	def process_one_casee_mode_0002(self, lrp_output_dictionary, case_number):
		print("    Processing mode:0002")

		this_filter_name = 'fraction_pass_filter'
		for filter_interval in self.frange:			
			'''
			This is where you want to customized if you want to observer different values.
			'''
			normalized_mean = self.compute_normalized_mean_by_channel(lrp_output_dictionary, this_filter_name, filter_interval)
			this_unit = {
				'case_number':case_number,
				'normalized_mean': normalized_mean
			}
			if filter_interval in self.pfilter_data_0002:
				self.pfilter_data_0002[filter_interval].append(this_unit)
			else:
				self.pfilter_data_0002[filter_interval] = [this_unit]
		# if verbose>=100: self.print_aux_0001('pfilter_data_0002')

		this_filter_name = 'fraction_clamp_filter'
		for filter_interval in self.crange:
			normalized_mean = self.compute_normalized_mean_by_channel(lrp_output_dictionary, this_filter_name, filter_interval)
			this_unit = {
				'case_number':case_number,
				'normalized_mean': normalized_mean
			}
			if filter_interval in self.cfilter_data_0002:
				self.cfilter_data_0002[filter_interval].append(this_unit)
			else:
				self.cfilter_data_0002[filter_interval] = [this_unit]

	def set_lrp_folder_dir(self, foldername):
		self.lrp_folder_dir = os.path.join(self.model_dir, foldername) 
		if self.verbose>100: print("  EvalLRP(). set_lrp_folder_dir(). %s"%(str(self.lrp_folder_dir)))

	def process_one_case(self, case_number, lrp_output_dictionary, x1=None, y0=None, processing_mode=None, verbose=0):
		print("  EvalLRP(). process_one_case(). Case number:%s"%(str(case_number)))
		self.get_filter_ranges(lrp_output_dictionary,verbose=verbose)
		if processing_mode=='0002':
			self.process_one_casee_mode_0002(lrp_output_dictionary, case_number)
		elif processing_mode=='0003':
			self.process_one_case_mode_0003(lrp_output_dictionary, x1, case_number,verbose=verbose)
		else:
			raise Exception('Invalid mode')

	def get_filter_ranges(self, lrp_output_dictionary,verbose=0):
		this_filter_name = 'fraction_pass_filter'
		if self.frange is None:
			self.frange = self.get_filter_range(this_filter_name, lrp_output_dictionary, verbose=verbose)
		this_filter_name = 'fraction_clamp_filter'
		if self.crange is None:
			self.crange = self.get_filter_range('fraction_clamp_filter', lrp_output_dictionary, verbose=verbose)

	def get_filter_range(self, filter_name, lrp_output_dictionary, verbose=0):
		filter_range = []
		if verbose>=250: print('    filter_name:%s'%(filter_name))
		for xkey in lrp_output_dictionary:
			if xkey[0] == filter_name:
				filter_interval = (xkey[1],xkey[2])
				filter_range.append(filter_interval)
				if verbose>=250: print('      %s'%(str(filter_interval)))
		return filter_range

	def compute_normalized_mean_by_channel(self, lrp_output_dictionary, this_filter_name, filter_interval):
		x = lrp_output_dictionary[(this_filter_name,filter_interval[0],filter_interval[1])]
		# x shape is for example (6,192,192,19), which is a single LRP output
		x_abs_max = np.max(abs(x))
		norm_mean_values = {'factor':x_abs_max, 'values': []}
		for xc in x:
			norm_mean_values['values'].append(np.mean(xc/x_abs_max))
			# print("            xc.shape: %s"%(str(xc.shape)))
		norm_mean_values['values'] = np.array(norm_mean_values['values'],dtype=np.float)
		return norm_mean_values

	def print_pfilter_data_0002(self):
		self.print_aux_0001('pfilter_data_0002')

	def print_cfilter_data_0002(self):
		self.print_aux_0001('cfilter_data_0002')

	def print_pfilter_data_0003(self):
		self.print_aux_0003('pfilter_data_0003')

	def print_cfilter_data_0003(self):
		self.print_aux_0003('cfilter_data_0003')

	def print_aux_0003(self,data_name):
		if data_name == 'pfilter_data_0003':
			data = self.pfilter_data_0003
		elif data_name == 'cfilter_data_0003':
			data = self.cfilter_data_0003
		for xkey in data:
			print('        filter_interval (key):%s'%(str(xkey)))		
			for this_unit in data[xkey]:
				print('          this_unit["case_number"]:%s'%(str(this_unit['case_number'])))
				print('            this_unit["bLRPtoOT"].shape:%s'%(str(this_unit["bLRPtoOT"].shape)))
				print('            this_unit["bLRPtobx"].shape:%s'%(str(this_unit["bLRPtobx"].shape)))
				
	def print_aux_0001(self, data_name):
		if data_name == 'pfilter_data_0002':
			data = self.pfilter_data_0002
		elif data_name == 'cfilter_data_0002':
			data = self.cfilter_data_0002
		print('      %s'%(data_name))
		for xkey in data:
			print('        filter_interval (key):%s'%(str(xkey)))
			for this_unit in data[xkey]:
				print('          this_unit["case_number"]:%s'%(str(this_unit['case_number'])))
				print('            this_unit["normalized_mean"]["factor"] = %s '%(str(this_unit['normalized_mean']['factor'])))
				print('            this_unit["normalized_mean"]["values"]:\n            ',end='')
				for value in this_unit['normalized_mean']['values']:
					print('%10s|'%(round(value,6)), end='')
				print()	

class EvalObj(object):
	def __init__(self):
		super(EvalObj, self).__init__()
		self.scores = {}
		self.dice_scores_labelled = {}
		'''
		Arrange by epochs:
		self.scores = { n_epoch : {}}

		example:
		self.scores = {
			1: {
				'dice_list' : average_dice,	
			},
			2: { ... },
			3: { ... },
			...
		}
		self.dice_scores_labelled = {
			epoch1: {
				case_number1: dice2
			},
			epoch2: {
				case)number2: dec2
			},...
		}

		Usage example:
		  see visual_header.py. lrp_UNet3D_filter_sweep_0002_visualizer_aux()
		'''
		
	def get_dice_score_at_epoch(self, epoch, dice_list):
		self.scores[epoch] = {}
		self.scores[epoch]['dice_list'] = dice_list
		# print("    dice_list mean:%s"%(str(np.mean(dice_list))))

	def get_dice_score_latest(self,dice_list):
		self.scores['latest'] = {}
		self.scores['latest']['dice_list'] = dice_list

	def save_evaluation(self, config_data, report_name='report.txt'):
		print('  evalobj.py. EvalObj.save_evaluation(): '+str(report_name))
		report_dir = os.path.join(config_data['working_dir'], config_data['relative_checkpoint_dir'],config_data['model_label_name'])
		report_full_path = os.path.join(report_dir,report_name)

		txt = open(report_full_path, 'w')
		print("   %5s | %s"%("epoch", "dice_score"))
		txt.write(" %5s | %s\n"%("epoch", "dice_score"))
		for epoch in self.scores:
			avg_dice_score = np.mean(self.scores[epoch]['dice_list'])
			print("   %5s | %s"%(str(epoch), str(avg_dice_score)))
			txt.write(" %5s | %s\n"%(str(epoch), str(avg_dice_score)))
			if DEBUG_SHOW_STORED_METRICS:
				print("      save_evaluation() epoch %s.\n      %s"%(\
					str(epoch),str(self.scores[epoch]['dice_list'])))
		txt.close()

	def save_one_case_evaluation(self, case_number, y, y_ot, config_data, dice=True, filename= 'output_report.txt'):
		'''
		y is the predicted output. torch tensor. The shape has to be (1,d,h,w) or (1,w,h,d)
		y_ot is the ground truth. torch tensor. The shape has to be (1,d,h,w) or (1,w,h,d)
		'''
		output_dir = os.path.join(config_data['working_dir'], config_data['relative_checkpoint_dir'], 
			config_data['model_label_name'],'output')
		save_full_path = os.path.join(output_dir,filename)

		txt_mode = 'w'
		if os.path.exists(save_full_path): txt_mode = 'a'
		
		txt = open(save_full_path, txt_mode)
		txt.write("case_number:%s\n"%(str(case_number)))
		if dice: 
			dice_score, dice_score2 = self.compute_dice_one_case_and_save(y,y_ot)
			txt.write("  dice score = %s [%s]\n"%(str(round(dice_score,7)), str(round(dice_score2,7))))
		txt.close()
		return dice_score,dice_score2

	def compute_dice_one_case_and_save(self, y,y_ot):
		'''
		y is the predicted output. torch tensor. The shape has to be (1,d,h,w) or (1,w,h,d)
		y_ot is the ground truth. torch tensor. The shape has to be (1,d,h,w) or (1,w,h,d)
		'''
		# 1.
		dice_loss = uloss.SoftDiceLoss()
		d = dice_loss(y, y_ot , factor=1)
		dice_score = 1 - d.item()

		# 2. 
		dice_score2 = me.DSC(y,y_ot).item()
		return dice_score, dice_score2


class LossTracker(object):
	"""docstring for LossTracker"""
	def __init__(self, config_data, display_every_n_minibatchs=10):
		super(LossTracker, self).__init__()
		self.display_every_n_minibatchs = display_every_n_minibatchs
		self.loss_name = 'someLoss'

		model_dir = os.path.join(config_data['working_dir'], config_data['relative_checkpoint_dir'],config_data['model_label_name'])
		self.model_dir = model_dir
		self.plot_fullpath = os.path.join(model_dir,config_data['model_label_name'] +"_loss_temp" + '.jpg')
		self.plot_fullpath_without_extension = os.path.join(model_dir,config_data['model_label_name'] +"_loss_")
		
		self.running_count= 0
		self.running_error = []
		self.global_error = []
		self.running_loss = 0.
		self.global_count = 0
		
		self.avg_loss = []
		self.loss_var = []
		self.k_th_global_step = []

	def store_loss(self, loss, realtime_plot=True):
		self.running_loss = self.running_loss + float(loss.item())
		self.running_error.append(float(loss.item()))
		self.running_count = self.running_count + 1
		self.global_count = self.global_count + 1
		self.global_error.append(float(loss.item()))

		if self.running_count ==  self.display_every_n_minibatchs:
			self.avg_loss.append(self.running_loss/self.display_every_n_minibatchs)
			self.loss_var.append(np.var(self.running_error)**0.5)
			self.k_th_global_step.append(self.global_count)
			self.running_count= 0
			self.running_loss = 0.
			self.running_error = []
			if realtime_plot: self.save_loss_plot()

	def save_loss_plot(self, label_tag=None):
		error_signal = 0
		first_error_flag = 1
		# print("save_loss_plot(). Plot size:%s"%(str(len(self.k_th_global_step))))
		plt.figure()
		plt.plot(self.k_th_global_step,self.avg_loss)
		y = np.array(self.avg_loss)
		er = np.array(self.loss_var) + 1e-6
		plt.fill_between(self.k_th_global_step,y-er, y+er,color='r',alpha=0.2)
		plt.title(self.loss_name)
		plt.tight_layout()
		while True:
			if error_signal:
				if first_error_flag:
					print("utils/evalobj.py. LossTracker. In error loop.")
					first_error_flag = 0
			try:
				if label_tag is not None: plt.savefig(self.plot_fullpath_without_extension + str(label_tag) + '.jpg')
				else: plt.savefig(self.plot_fullpath)
				break
			except:
				error_signal = 1
		plt.close()

	def save_state(self, config_data, filename='loss_tracker.evalobj'):
		folder_path = os.path.join(config_data['working_dir'],config_data['relative_checkpoint_dir'], config_data['model_label_name'])
		filepath = os.path.join(folder_path, filename)
		output = open(filepath, 'wb')
		pickle.dump(self, output)
		output.close()


class CrossEntropyLossTracker(LossTracker):
	"""docstring for CrossEntropyLossTracker"""
	def __init__(self, config_data, display_every_n_minibatchs=10):
		super(CrossEntropyLossTracker, self).__init__(config_data, display_every_n_minibatchs=display_every_n_minibatchs)
		self.loss_name = 'CrossEntropyLoss'
		self.plot_fullpath = os.path.join(self.model_dir,config_data['model_label_name'] +"_" + self.loss_name+"_temp" + '.jpg')
		self.plot_fullpath_without_extension = os.path.join(self.model_dir,config_data['model_label_name'] +"_" + self.loss_name+ "_")

	def load_state(self, config_data, filename='loss_tracker.evalobj'):
		folder_path = os.path.join(config_data['working_dir'],config_data['relative_checkpoint_dir'], config_data['model_label_name'])
		filepath = os.path.join(folder_path, filename)
		if os.path.exists(filepath):
			print("    CrossEntropyLossTracker().Loading...",end='')	
			pkl_file = open(filepath, 'rb')
			losstracker = pickle.load(pkl_file)
			pkl_file.close() 
		else:
			print("    CrossEntropyLossTracker().Initiate new...",end='')
			losstracker = CrossEntropyLossTracker(config_data)
		print("Done.")
		return losstracker